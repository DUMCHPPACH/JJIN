{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10_순환신경망.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_xB-w8xU10X",
        "outputId": "5452dd53-d1b6-4f02-d297-41cff4d46d41"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "timesteps = 10 # 시점의 수. NLP에서는 보통 문장의 길이가 된다.\n",
        "input_size = 4 # 입력의 차원. NLP에서는 보통 단어 벡터의 차원이 된다.\n",
        "hidden_size = 8 # 은닉 상태의 크기. 메모리 셀의 용량이다.\n",
        "\n",
        "inputs = np.random.random((timesteps, input_size)) # 입력에 해당되는 2D 텐서\n",
        "\n",
        "hidden_state_t = np.zeros((hidden_size,)) # 초기 은닉 상태는 0(벡터)로 초기화\n",
        "# 은닉 상태의 크기 hidden_size로 은닉 상태를 만듬.\n",
        "print(hidden_state_t) # 은닉상태의 크기를 8로 정의하였으므로 8차원을 가지는 0값으로 구성된 벡터 출력\n",
        "\n",
        "Wx = np.random.random((hidden_size, input_size))  # (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치.\n",
        "Wh = np.random.random((hidden_size, hidden_size)) # (8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치.\n",
        "b = np.random.random((hidden_size,)) # (8,)크기의 1D 텐서 생성. 이 값은 편향(bias).\n",
        "\n",
        "print(np.shape(Wx))\n",
        "print(np.shape(Wh))\n",
        "print(np.shape(b))\n",
        "\n",
        "total_hidden_states = []\n",
        "\n",
        "# 메모리 셀 동작\n",
        "for input_t in inputs: # 각 시점에 따라서 입력값이 입력됨.\n",
        "  output_t = np.tanh(np.dot(Wx,input_t) + np.dot(Wh,hidden_state_t) + b) # Wx * Xt + Wh * Ht-1 + b(bias)\n",
        "  total_hidden_states.append(list(output_t)) # 각 시점의 은닉 상태의 값을 계속해서 축적\n",
        "  print(np.shape(total_hidden_states)) # 각 시점 t별 메모리 셀의 출력의 크기는 (timestep, output_dim)\n",
        "  hidden_state_t = output_t\n",
        "\n",
        "total_hidden_states = np.stack(total_hidden_states, axis = 0) \n",
        "# 출력 시 값을 깔끔하게 해준다.\n",
        "\n",
        "print(total_hidden_states) # (timesteps, output_dim)의 크기. 이 경우 (10, 8)의 크기를 가지는 메모리 셀의 2D 텐서를 출력."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "(8, 4)\n",
            "(8, 8)\n",
            "(8,)\n",
            "(1, 8)\n",
            "(2, 8)\n",
            "(3, 8)\n",
            "(4, 8)\n",
            "(5, 8)\n",
            "(6, 8)\n",
            "(7, 8)\n",
            "(8, 8)\n",
            "(9, 8)\n",
            "(10, 8)\n",
            "[[0.96068225 0.6573336  0.94199226 0.90272863 0.93217811 0.77634275\n",
            "  0.87905846 0.57051252]\n",
            " [0.99997764 0.9995663  0.99993447 0.99989094 0.9999012  0.99982186\n",
            "  0.99997366 0.99988744]\n",
            " [0.99999546 0.99978979 0.99996751 0.9999778  0.99998497 0.99994384\n",
            "  0.9999883  0.99995665]\n",
            " [0.9999974  0.99987741 0.9999867  0.9999844  0.9999898  0.9999571\n",
            "  0.99999501 0.99996442]\n",
            " [0.99999455 0.99992467 0.99998851 0.99998719 0.99999232 0.99996637\n",
            "  0.99999512 0.99994881]\n",
            " [0.99999555 0.99989311 0.99999023 0.99997998 0.99999079 0.99995738\n",
            "  0.99999556 0.99993526]\n",
            " [0.99999561 0.99993241 0.9999846  0.9999916  0.99999319 0.99996994\n",
            "  0.99999447 0.9999676 ]\n",
            " [0.99997589 0.99966599 0.99994537 0.99993401 0.99995862 0.99993004\n",
            "  0.99997024 0.99988333]\n",
            " [0.99999625 0.99992013 0.99998805 0.99998852 0.99999202 0.99996621\n",
            "  0.99999534 0.99996233]\n",
            " [0.99999291 0.99994447 0.99998272 0.99999254 0.9999941  0.99997282\n",
            "  0.99999359 0.99996084]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRi-EaqLVK8K",
        "outputId": "ca89953d-f583-40fe-a30f-510a199bc675"
      },
      "source": [
        "#nn.RNN\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_size = 5 # 입력의 크기  / 매번 들어가는!!\n",
        "hidden_size = 8 # 은닉 상태의 크기\n",
        "\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs = torch.Tensor(1, 10, 5)\n",
        "\n",
        "cell = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "outputs, _status = cell(inputs)\n",
        "\n",
        "print(outputs.shape) # 모든 time-step의 hidden_state\n",
        "torch.Size([1, 10, 8])\n",
        "\n",
        "print(_status.shape) # 최종 time-step의 hidden_state\n",
        "torch.Size([1, 1, 8])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 8])\n",
            "torch.Size([1, 1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5ZpMkdyVtPX",
        "outputId": "06e44a20-d307-48aa-bca6-ebc8e94bc39c"
      },
      "source": [
        "#깊은 순환 신경망\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs = torch.Tensor(1, 10, 5)\n",
        "cell = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True, bidirectional = True)\n",
        "outputs, _status = cell(inputs)\n",
        "print(outputs.shape) # (배치 크기, 시퀀스 길이, 은닉 상태의 크기 x 2)\n",
        "torch.Size([1, 10, 16])\n",
        "\n",
        "print(_status.shape) # (층의 개수 x 2, 배치 크기, 은닉 상태의 크기)\n",
        "torch.Size([4, 1, 8])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 16])\n",
            "torch.Size([4, 1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDPlRAK2V0mX",
        "outputId": "f96d8349-7986-4652-d600-650eeae6ff82"
      },
      "source": [
        "##양방향 순환신경망\n",
        "\n",
        "# (batch_size, time_steps, input_size)\n",
        "inputs = torch.Tensor(1, 10, 5)\n",
        "cell = nn.RNN(input_size = 5, hidden_size = 8, num_layers = 2, batch_first=True, bidirectional = True)\n",
        "outputs, _status = cell(inputs)\n",
        "print(outputs.shape) # (배치 크기, 시퀀스 길이, 은닉 상태의 크기 x 2)\n",
        "torch.Size([1, 10, 16])\n",
        "\n",
        "print(_status.shape) # (층의 개수 x 2, 배치 크기, 은닉 상태의 크기)\n",
        "torch.Size([4, 1, 8])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 16])\n",
            "torch.Size([4, 1, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTIAoURGW-6U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}